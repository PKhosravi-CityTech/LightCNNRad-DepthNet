{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/PKhosravi-CityTech/LightCnnRad/raw/main/Images/BioMindLogo.png\" alt=\"BioMind AI Lab Logo\" width=\"150\" height=\"150\" align=\"left\" style=\"margin-bottom: 40px;\"> **Repository Developed by Pegah Khosravi, Principal Investigator of the BioMind AI Lab**\n",
    "\n",
    "Welcome to this repository! This repository is a result of collaborative efforts from our dedicated team at the lab. We are committed to advancing the field of biomedical AI and pushing the boundaries of medical data analysis. Your interest and contributions to our work are greatly appreciated. For more information about our lab and ongoing projects, please visit the [BioMind AI Lab website](https://sites.google.com/view/biomind-ai-lab). Thank you for your interest and support!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import csv\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the availibility of GPU for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Optional: Ensures that every run on the same machine yields the same result\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining transforms and dataloaders and training the VGG-16 model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "data_dir = \"Datasets/Alzheimer MRI\"\n",
    "\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = {\n",
    "    'Train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],  # Normalizes pixel values to [-1, 1]\n",
    "                             [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'Validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],  # Normalizes pixel values to [-1, 1]\n",
    "                             [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'Test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],  # Normalizes pixel values to [-1, 1]\n",
    "                             [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Defining classes\n",
    "classes = os.listdir(os.path.join(data_dir, 'Test'))\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in ['Train', 'Validation']\n",
    "}\n",
    "\n",
    "\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
    "    for x in ['Train', 'Validation']\n",
    "}\n",
    "\n",
    "\n",
    "# Load the VGG16 model without pre-trained weights\n",
    "model = models.vgg16(pretrained=False)\n",
    "\n",
    "# Modify the classifier for binary classification (2 classes)\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "\n",
    "# Send the model to the selected device (CPU or GPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize the weights of the model (optional but recommended when training from scratch)\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model.apply(weights_init)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "accuracies_dic = {'Train': [], 'Validation': []}\n",
    "losses_dic = {'Train': [], 'Validation': []}\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=100):\n",
    "    # Model training and saving best model\n",
    "    best_accuracy = 0.0\n",
    "    patience = 5  # Number of epochs to wait after last time validation accuracy improved.\n",
    "    patience_counter = 0  # Counter to track the number of epochs since the last improvement\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['Train', 'Validation']:\n",
    "            if phase == 'Train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'Train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'Train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "            epoch_acc = corrects.double() / len(dataloaders[phase].dataset)\n",
    "            losses_dic[phase].append(epoch_loss)\n",
    "            accuracies_dic[phase].append(epoch_acc.cpu().numpy().item())\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} - {phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            if phase == 'Validation':\n",
    "                if epoch_acc > best_accuracy:\n",
    "                    torch.save(model.state_dict(), 'best_checkpoint.model')\n",
    "                    best_accuracy = epoch_acc\n",
    "                    patience_counter = 0  # Reset counter\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "        if patience_counter > patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break  # Exit from the training loop\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloaders, criterion, optimizer, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the trained-from-scratch VGG-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=torch.load(\"best_checkpoint.model\")\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of test set for the trained-from-scratch VGG-16 (Image-based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img_path, transformer, model):\n",
    "    model.eval()\n",
    "    image = Image.open(img_path)\n",
    "    image_tensor = transformer(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor = image_tensor.cuda()\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients during inference\n",
    "        input = Variable(image_tensor)\n",
    "        output = model(input)\n",
    "\n",
    "    prob = nn.functional.softmax(output, dim=1)\n",
    "    prob = prob.cpu().detach().numpy()  # Move the tensor to CPU and then convert to numpy\n",
    "    return prob\n",
    "\n",
    "classes = os.listdir(os.path.join(data_dir, 'Test'))\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "pred_path = os.path.join(data_dir, 'Test')\n",
    "\n",
    "images_path = glob.glob(pred_path + '/**/*.png')\n",
    "pred_dict = {}\n",
    "\n",
    "for i in images_path:\n",
    "    filename = i[i.rfind('/') + 1:]\n",
    "    prob_array = prediction(i, data_transforms['Test'], model)\n",
    "    pred_dict[filename] = prob_array\n",
    "\n",
    "# Print the probabilities in the desired format\n",
    "for filename, prob_array in pred_dict.items():\n",
    "    print(f\"'{filename}': np.array({np.array2string(prob_array, separator=', ', formatter={'float_kind': lambda x: f'{x:.8e}'} )}, dtype=np.float32),\")\n",
    "\n",
    "\n",
    "# Define the path for saving the CSV file\n",
    "output_csv_path = 'train_from_scratch_predictions.csv'\n",
    "\n",
    "# Save prediction results to CSV\n",
    "with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['Label', 'Predicted Class', 'Probability'])\n",
    "\n",
    "    for filename, prob_array in pred_dict.items():\n",
    "        predicted_class = classes[1] if prob_array[0][1] > 0.5 else classes[0]  # Adjust the threshold as needed\n",
    "        probability = prob_array[0][1]\n",
    "        csvwriter.writerow([filename.split('\\\\')[-2], predicted_class, probability])\n",
    "\n",
    "print(\"Prediction results saved to\", output_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of test set for the trained-from-scratch VGG-16 (Patient-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def prediction(img_path, transformer, model):\n",
    "    model.eval()\n",
    "    image = Image.open(img_path)\n",
    "    image_tensor = transformer(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor = image_tensor.cuda()\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients during inference\n",
    "        input = Variable(image_tensor)\n",
    "        output = model(input)\n",
    "\n",
    "    prob = nn.functional.softmax(output, dim=1)\n",
    "    prob = prob.cpu().detach().numpy()  # Move the tensor to CPU and then convert to numpy\n",
    "    return prob\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "pred_path = os.path.join(data_dir, 'Test')\n",
    "\n",
    "images_path = glob.glob(pred_path + '/**/*.png')\n",
    "pred_dict = {}\n",
    "\n",
    "for i in images_path:\n",
    "    filename = i[i.rfind('/') + 1:]\n",
    "    prob_array = prediction(i, data_transforms['Test'], model)\n",
    "    pred_dict[filename] = prob_array\n",
    "\n",
    "# Print the probabilities in the desired format\n",
    "for filename, prob_array in pred_dict.items():\n",
    "    print(f\"'{filename}': np.array({np.array2string(prob_array, separator=', ', formatter={'float_kind': lambda x: f'{x:.8e}'} )}, dtype=np.float32),\")\n",
    "\n",
    "\n",
    "# Set the desired threshold for considering predictions as positive\n",
    "positive_threshold = 0.5\n",
    "\n",
    "# Define the path for saving the CSV file\n",
    "output_csv_path = 'train_from_scratch_predictions_vote.csv'\n",
    "\n",
    "# Dictionary to store patient-wise predictions\n",
    "patient_predictions = {}\n",
    "\n",
    "# Populate the dictionary with individual image predictions\n",
    "for filename, prob_array in pred_dict.items():\n",
    "    patient_id = \"_\".join(filename.split('_')[:-1]) \n",
    "    prediction = prob_array[0][1]\n",
    "\n",
    "    if patient_id not in patient_predictions:\n",
    "        patient_predictions[patient_id] = []\n",
    "\n",
    "    patient_predictions[patient_id].append(prediction)\n",
    "\n",
    "# Calculate majority vote and save results to CSV\n",
    "with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['Label', 'Predicted Class', 'Probability'])\n",
    "\n",
    "    for patient_id, predictions in patient_predictions.items():\n",
    "        majority_vote = sum(predictions) / len(predictions)\n",
    "        predicted_class = classes[1] if majority_vote > positive_threshold else classes[0]\n",
    "        if majority_vote >= positive_threshold or (1 - majority_vote) >= positive_threshold:\n",
    "            csvwriter.writerow([patient_id.split('\\\\')[-2], predicted_class, majority_vote])  # Writing patient ID and majority vote prediction\n",
    "\n",
    "print(\"Prediction results saved to\", output_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting ROC curve for the VGG-16 model trained from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from predictions.csv\n",
    "df = pd.read_csv('train_from_scratch_predictions_vote.csv')\n",
    "\n",
    "# Extract true labels and predicted probabilities\n",
    "true_labels = df['Label']\n",
    "predicted_probs = df['Probability']\n",
    "\n",
    "# Convert labels to binary format (0 for 'N_' and 1 for 'Y_')\n",
    "true_labels = true_labels.apply(lambda x: 0 if x.startswith(classes[0]) else 1)\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, predicted_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve of VGG16 Model Trained from Scratch for \\n for Treatment Response Classification of \\n Breast Cancer MRI Dataset', pad=10)\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Save the figure to a PDF file\n",
    "plt.savefig('roc.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting confusion matrix and calculating accuracy, specificity, and sensitivity for the VGG-16 model trained from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file containing predictions\n",
    "df = pd.read_csv('train_from_scratch_predictions_vote.csv')\n",
    "\n",
    "# Extract true labels and predicted probabilities\n",
    "true_labels = df['Label']\n",
    "\n",
    "# Threshold to convert probabilities to binary predictions\n",
    "threshold = 0.5\n",
    "binary_predictions = np.where(df['Probability'] >= threshold, classes[1], classes[0])\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(true_labels, binary_predictions, labels=classes)\n",
    "\n",
    "# Extract TP, TN, FP, FN from confusion matrix\n",
    "tp = cm[1, 1]\n",
    "tn = cm[0, 0]\n",
    "fp = cm[0, 1]\n",
    "fn = cm[1, 0]\n",
    "\n",
    "# Calculate accuracy, sensitivity (True Positive Rate), and specificity (True Negative Rate)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Display TP, TN, FP, FN\n",
    "print(\"True Positive:\", tp)\n",
    "print(\"True Negative:\", tn)\n",
    "print(\"False Positive:\", fp)\n",
    "print(\"False Negative:\", fn)\n",
    "\n",
    "# Display accuracy, sensitivity, and specificity\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity (True Positive Rate):\", sensitivity)\n",
    "print(\"Specificity (True Negative Rate):\", specificity)\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))  # Adjusted figure size for better visibility\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='magma', xticklabels=classes, yticklabels=classes)  # Using 'g' as fmt to avoid scientific notation\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title(\"Confusion Matrix of VGG16 Model Trained from Scratch for \\n Treatment Response Classification of \\n Breast Cancer MRI Dataset\", pad=10)\n",
    "\n",
    "\n",
    "# Save the figure to a PDF file\n",
    "plt.savefig('confusion_matrix.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
